{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e4caa28",
   "metadata": {},
   "source": [
    "# 🧪 Summary of Hypothesis Testing  \n",
    "\n",
    "Hypothesis testing is a **formal statistical method** used to decide whether there is enough evidence from sample data to support a claim (hypothesis) about a **population parameter**. It bridges the gap between **sample statistics** and **population inferences**.  \n",
    "\n",
    "---\n",
    "\n",
    "## 📌 **1. What is Hypothesis Testing?**  \n",
    "Hypothesis testing allows us to:  \n",
    "- Evaluate a **claim** (e.g., “The average recovery time is reduced with a new drug”).  \n",
    "- Use **sample evidence** to infer something about an **entire population**.  \n",
    "- Control the risk of making incorrect decisions using probability theory.  \n",
    "\n",
    "---\n",
    "\n",
    "## ⚙ **2. Key Components**  \n",
    "\n",
    "- **Null Hypothesis (\\(H_0\\))**  \n",
    "  - The **default assumption** or **status quo**.  \n",
    "  - Represents **no effect**, **no difference**, or **no change**.  \n",
    "  - *Example*: “The new drug has **no effect** on recovery time.”  \n",
    "\n",
    "- **Alternative Hypothesis (\\(H_1\\) or \\(H_a\\))**  \n",
    "  - Represents what the **researcher aims to prove**.  \n",
    "  - Indicates **an effect**, **a difference**, or **a change** exists.  \n",
    "  - *Example*: “The new drug **does affect** recovery time.”  \n",
    "\n",
    "---\n",
    "\n",
    "## 🧭 **3. Steps in Hypothesis Testing**  \n",
    "\n",
    "1. **Formulate the Hypotheses**  \n",
    "   - Clearly state \\(H_0\\) and \\(H_a\\).  \n",
    "   - Decide if the test is **one-tailed** or **two-tailed**.  \n",
    "\n",
    "2. **Choose Significance Level (\\(\\alpha\\))**  \n",
    "   - Probability of **rejecting \\(H_0\\) when it is actually true** (Type I error).  \n",
    "   - Common choices:  \n",
    "     - \\(\\alpha = 0.05\\) → 5% risk.  \n",
    "     - \\(\\alpha = 0.01\\) → 1% risk (more stringent).  \n",
    "\n",
    "3. **Calculate the Test Statistic**  \n",
    "   - Compute a value (e.g., z-score, t-score) that measures **how far your sample statistic is from the null hypothesis expectation**.  \n",
    "   - Formula depends on test type: z-test, t-test, chi-square, ANOVA, etc.  \n",
    "\n",
    "4. **Determine the p-value**  \n",
    "   - The **p-value** is the probability of observing results **as extreme or more extreme than your sample**, assuming \\(H_0\\) is true.  \n",
    "   - A **low p-value** indicates your sample is **unlikely** under \\(H_0\\).  \n",
    "\n",
    "5. **Make a Decision**  \n",
    "   - **If \\(p \\leq \\alpha\\)** → Reject \\(H_0\\). Evidence supports \\(H_a.\\)  \n",
    "   - **If \\(p > \\alpha\\)** → Fail to reject \\(H_0\\). Evidence is insufficient to support \\(H_a.\\)  \n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 **4. Key Notes**  \n",
    "\n",
    "- ✅ **Type I Error**: Rejecting \\(H_0\\) when it is true (false positive).  \n",
    "- ❌ **Type II Error**: Failing to reject \\(H_0\\) when it is false (false negative).  \n",
    "- 📊 **Power of a Test**: Probability of correctly rejecting \\(H_0\\) when \\(H_a\\) is true.  \n",
    "\n",
    "---\n",
    "\n",
    "## 📈 **Example Scenario**  \n",
    "\n",
    "**Claim**: A new teaching method improves test scores.  \n",
    "- \\(H_0\\): The new method **does not improve** scores (\\(\\mu = \\mu_0\\)).  \n",
    "- \\(H_a\\): The new method **improves** scores (\\(\\mu > \\mu_0\\)).  \n",
    "- Collect sample data, calculate the test statistic and p-value.  \n",
    "- If \\(p = 0.03\\) and \\(\\alpha = 0.05\\): Reject \\(H_0\\) → Evidence supports improvement.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8016ceae",
   "metadata": {},
   "source": [
    "# 📊 Understanding P-Values and Significance Levels  \n",
    "\n",
    "## 🔢 **1. P-Value**  \n",
    "- **Definition:** The probability of observing results **as extreme as** (or more extreme than) the test statistic, **assuming the Null Hypothesis (\\(H_0\\)) is true**.  \n",
    "- **Interpretation:**  \n",
    "  - Smaller p-values → **Stronger evidence** **against \\(H_0\\)**.  \n",
    "  - A large p-value means the observed data is consistent with \\(H_0\\).  \n",
    "- **Example:**  \n",
    "  If \\(p = 0.02\\) under \\(H_0\\), there is only a **2% chance** of observing such an extreme result if the null hypothesis is actually true.  \n",
    "\n",
    "---\n",
    "\n",
    "## ⚖ **2. Significance Level (\\(\\alpha\\))**  \n",
    "- **Definition:** The **threshold** for deciding whether to reject \\(H_0.\\)  \n",
    "- **Common Choices:**  \n",
    "  - \\(\\alpha = 0.05\\) → **5% risk** of a Type I error (rejecting \\(H_0\\) when it is actually true).  \n",
    "  - \\(\\alpha = 0.01\\) → **1% risk** (more stringent test).  \n",
    "- **Analogy:** Think of \\(\\alpha\\) as the “cut-off” line: if your p-value crosses it, you treat the result as statistically significant.  \n",
    "\n",
    "---\n",
    "\n",
    "## 📏 **3. Decision Rule**  \n",
    "\n",
    "| Condition              | Decision                   | Interpretation                                    |\n",
    "|------------------------|---------------------------|--------------------------------------------------|\n",
    "| \\(p \\leq \\alpha\\)      | Reject \\(H_0\\)            | Evidence suggests the effect/difference is real. |\n",
    "| \\(p > \\alpha\\)         | Fail to Reject \\(H_0\\)    | Not enough evidence to support a real effect.    |\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 **4. Real-World Example**  \n",
    "**Scenario:** Testing whether a new fertilizer increases plant growth.  \n",
    "- Null Hypothesis (\\(H_0\\)): The fertilizer has **no effect** on growth.  \n",
    "- Alternative Hypothesis (\\(H_a\\)): The fertilizer **does increase** growth.  \n",
    "- Significance Level: \\(\\alpha = 0.05\\).  \n",
    "- You collect data and compute a p-value of **0.03**.  \n",
    "\n",
    "**Interpretation:**  \n",
    "- \\(p = 0.03 < 0.05\\) → Reject \\(H_0\\).  \n",
    "- Conclusion: There is statistically significant evidence that the fertilizer increases growth.  \n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 **5. Key Takeaways**  \n",
    "- ✅ **Smaller p-values** = stronger evidence against the null.  \n",
    "- ✅ \\(\\alpha\\) is a **pre-set threshold** to control error risk.  \n",
    "- ✅ **Failing to reject \\(H_0\\)** does **not** prove \\(H_0\\) is true—it only means insufficient evidence to reject it.  \n",
    "- ✅ Always report **both the p-value and \\(\\alpha\\)** for transparency.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79c9f54",
   "metadata": {},
   "source": [
    "# ✅ Types of Errors in Hypothesis Testing\n",
    "\n",
    "When performing a hypothesis test, you decide to **reject** or **fail to reject** the null hypothesis (\\(H_0\\)).  \n",
    "Because decisions are based on **sample data** (not the entire population), **mistakes can happen**.  \n",
    "There are **two main types of errors**:\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣ **Type I Error (False Positive)**  \n",
    "- **Symbol:** \\(\\alpha\\) (alpha)  \n",
    "- **Definition:** Rejecting \\(H_0\\) when it is **actually true**.  \n",
    "- **Simple Explanation:** You conclude there **is an effect** when there really **isn't one**.  \n",
    "- **Example (Medical Trial):** Concluding a **new drug works** when, in fact, it performs **no better than a placebo**.  \n",
    "- **Significance Level (\\(\\alpha\\)):**  \n",
    "  - Directly controlled by the researcher.  \n",
    "  - Common choice: \\(\\alpha = 0.05\\) → Accept a **5% risk** of a **false positive**.  \n",
    "\n",
    "---\n",
    "\n",
    "## 2️⃣ **Type II Error (False Negative)**  \n",
    "- **Symbol:** \\(\\beta\\) (beta)  \n",
    "- **Definition:** Failing to reject \\(H_0\\) when it is **actually false**.  \n",
    "- **Simple Explanation:** You conclude there **is no effect** when there **actually is one**.  \n",
    "- **Example (Medical Trial):** Concluding a **new drug doesn’t work** when, in fact, it **does work**.  \n",
    "- **Power of a Test:**  \n",
    "  - **Power = \\(1 - \\beta\\)** → Probability of correctly rejecting a false null hypothesis.  \n",
    "  - To **reduce \\(\\beta\\)** and **increase power**, you often need a **larger sample size**.\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 **The Decision Matrix**\n",
    "\n",
    "| **Your Decision**      | **Reality: \\(H_0\\) TRUE**      | **Reality: \\(H_0\\) FALSE**     |\n",
    "|------------------------|-------------------------------|-------------------------------|\n",
    "| **Reject \\(H_0\\)**     | ❌ Type I Error (False Positive) | ✅ Correct Decision            |\n",
    "| **Fail to Reject \\(H_0\\)** | ✅ Correct Decision             | ❌ Type II Error (False Negative) |\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 **Key Takeaways**\n",
    "- 🎯 **Type I error (\\(\\alpha\\))** = Rejecting a true \\(H_0\\).  \n",
    "- 🎯 **Type II error (\\(\\beta\\))** = Failing to reject a false \\(H_0.\\)  \n",
    "- ⚖ **Trade-off:** Lowering \\(\\alpha\\) (making tests stricter) **increases \\(\\beta\\)** unless sample size is increased.  \n",
    "- 📈 **Power (\\(1-\\beta\\))** represents the ability to detect a real effect.  \n",
    "- 🧠 **Practical Example:**  \n",
    "  - Drug trials often choose **small \\(\\alpha\\)** (e.g., 0.01) to avoid approving ineffective drugs.  \n",
    "  - In other fields, avoiding **Type II errors** (missing real effects) may be more important.  \n",
    "\n",
    "---\n",
    "\n",
    "### 💡 **Tip for Analysts**\n",
    "Always **report both \\(\\alpha\\)** (significance level) **and power (\\(1-\\beta\\))** when designing or interpreting tests. This ensures transparency about risks of both types of errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93066feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic:  0.9408750722807707\n",
      "P-Value:  0.383088241586687\n",
      "Fail to Reject the null hypothese: no significant difference\n"
     ]
    }
   ],
   "source": [
    "######################################## Exercise 1 ########################################\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Sample data\n",
    "data = [12, 14,15, 16, 17, 18, 19]\n",
    "\n",
    "# Null Hypothesis: mean = 15\n",
    "population_mean = 15\n",
    "\n",
    "# Perform t-test\n",
    "t_stat, p_value = ttest_1samp(data, population_mean)\n",
    "print(\"T-Statistic: \", t_stat)\n",
    "print(\"P-Value: \", p_value)\n",
    "\n",
    "# Interpret Results\n",
    "alpha = 0.05\n",
    "if p_value <= alpha:\n",
    "      print(\"Reject the null hypothesis: significant difference\")\n",
    "else:\n",
    "    print(\"Fail to Reject the null hypothese: no significant difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e17d3c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic:  0.7761823345023016\n",
      "P-value:  0.45266873983452593\n",
      "Fail to Reject the null hypothese: no significant difference\n"
     ]
    }
   ],
   "source": [
    "######################################## Exercise 2 ########################################\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "\n",
    "group1 = [12, 14, 15, 16, 17, 18, 19]\n",
    "group2 = [11, 13, 14, 15, 16, 17, 18]\n",
    "\n",
    "t_stat, p_value = ttest_ind(group1, group2)\n",
    "print(\"T-statistic: \", t_stat)\n",
    "print(\"P-value: \", p_value)\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value <= alpha:\n",
    "      print(\"Reject the null hypothesis: significant difference\")\n",
    "else:\n",
    "    print(\"Fail to Reject the null hypothese: no significant difference\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e40882a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z-statistic: -2.5980762113533156\n",
      "p-value: 0.009374768459434968\n",
      "میانگین نمونه به‌طور معناداری با مقدار 7 متفاوت است.\n"
     ]
    }
   ],
   "source": [
    "######################################## Exercise 3 ########################################\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Making a dataset\n",
    "data = [1, 2, 3, 5, 5, 5, 7, 7, 7, 6, 8, 10] # Or a random dataset data = np.random.normal(loc = 160, scale = 1, size = 100)\n",
    "\n",
    "mean = np.mean(data)\n",
    "\n",
    "mu = 7\n",
    "\n",
    "n = len(data)\n",
    "\n",
    "sigma = 2\n",
    "z_test = (mean - mu) / (sigma / np.sqrt(n))\n",
    "\n",
    "# print(z_test)\n",
    "\n",
    "p_value = 2 * (1 - norm.cdf(abs(z_test)))\n",
    "\n",
    "print(\"z-statistic:\", z_test)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"میانگین نمونه به‌طور معناداری با مقدار 7 متفاوت است.\")\n",
    "else:\n",
    "    print(\"تفاوت معناداری مشاهده نشد.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be362acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic:  0.7761823345023016\n",
      "P-value:  0.45266873983452593\n",
      "Fail to Reject the null hypothese: no significant difference\n"
     ]
    }
   ],
   "source": [
    "######################################## Exercise 4 ########################################\n",
    "import numpy as np\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from scipy.stats import ttest_ind\n",
    "import pandas as pd \n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/refs/heads/master/iris.csv\"\n",
    "\n",
    "main_path = Path(\"data\")\n",
    "\n",
    "file_r = main_path.mkdir(exist_ok=True)\n",
    "main_path = main_path / \"iris.csv\"\n",
    "\n",
    "with open(main_path, \"w+\") as file:\n",
    "    file.write(requests.get(url).text)\n",
    "\n",
    "df = pd.read_csv(main_path)\n",
    "\n",
    "# df.describe() Describing data for more information\n",
    "\n",
    "column_sepal_length_setosa = [length \n",
    "                              for length, species in zip(df[\"sepal_length\"], df[\"species\"]) \n",
    "                              if species == \"setosa\"]\n",
    "\n",
    "column_sepal_length_setosa = [length \n",
    "                              for length, species in zip(df[\"sepal_length\"], df[\"species\"]) \n",
    "                              if species == \"virginica\"]\n",
    "\n",
    "\n",
    "t_stat, p_value = ttest_ind(group1, group2)\n",
    "print(\"T-statistic: \", t_stat)\n",
    "print(\"P-value: \", p_value)\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value <= alpha:\n",
    "      print(\"Reject the null hypothesis: significant difference\")\n",
    "else:\n",
    "    print(\"Fail to Reject the null hypothese: no significant difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04de315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b36c440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5f1fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
