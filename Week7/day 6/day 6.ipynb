{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76c59b55",
   "metadata": {},
   "source": [
    "# ‚ö†Ô∏è Problems Caused by Imbalanced Data in Classification Tasks\n",
    "\n",
    "---\n",
    "\n",
    "## üìå What is Imbalanced Data?\n",
    "\n",
    "**Imbalanced data** occurs when one class (or category) in a dataset has **significantly more samples** than the other(s).  \n",
    "In such cases, the model tends to favor the majority class, leading to poor performance on the minority class ‚Äî which is often the class of most interest (e.g., fraud, disease, or failure cases).\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öñÔ∏è Example\n",
    "\n",
    "Imagine a binary classification dataset for **fraud detection**:\n",
    "- 9,900 transactions are **legitimate**.\n",
    "- 100 transactions are **fraudulent**.\n",
    "\n",
    "The dataset is **99% vs 1%** imbalanced.\n",
    "\n",
    "If a naive model simply predicts *‚Äúlegitimate‚Äù* for every case:\n",
    "- It will have **99% accuracy**,  \n",
    "  yet **0% usefulness**, because it never detects fraud.\n",
    "\n",
    "---\n",
    "\n",
    "## üöß Challenges with Imbalanced Data\n",
    "\n",
    "### 1. üß† **Bias Toward the Majority Class**\n",
    "- Machine learning models tend to **prioritize the majority class**, since it dominates the training data.\n",
    "- The model learns patterns that favor the frequent class and ignores the rare one.\n",
    "- As a result, the **minority class gets misclassified** frequently.\n",
    "\n",
    "**Example:**  \n",
    "In disease detection, the model predicts ‚Äúhealthy‚Äù for almost all cases, missing critical rare disease cases.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. üìâ **Misleading Evaluation Metrics**\n",
    "- Common metrics like **accuracy** can be highly deceptive in imbalanced datasets.  \n",
    "  For example, a model that predicts all samples as the majority class can still appear to perform well by accuracy.\n",
    "\n",
    "#### ‚úÖ Better Metrics for Imbalanced Data:\n",
    "- **Precision:** Fraction of predicted positives that are correct.  \n",
    "- **Recall (Sensitivity):** Fraction of actual positives correctly identified.  \n",
    "- **F1-Score:** Harmonic mean of precision and recall.  \n",
    "- **AUC-ROC (Area Under Curve):** Measures the trade-off between true positive rate and false positive rate.\n",
    "\n",
    "**Example (Accuracy Trap):**\n",
    "| Class | Actual Count | Model Prediction | Accuracy Contribution |\n",
    "|--------|---------------|------------------|------------------------|\n",
    "| Majority (0) | 950 | Predicted correctly | ‚úÖ 950 |\n",
    "| Minority (1) | 50 | Predicted as 0 | ‚ùå 0 |\n",
    "| **Total Accuracy:** | | | **95%** (but 0% recall for minority class) |\n",
    "\n",
    "---\n",
    "\n",
    "### 3. üîç **Limited Information for Minority Class**\n",
    "- The **minority class** may have too few samples for the model to learn meaningful patterns.\n",
    "- This can lead to **underfitting** and **poor generalization** for the minority class.\n",
    "\n",
    "**Consequences:**\n",
    "- The model may never learn what distinguishes rare events (like fraud, diseases, or machine faults).\n",
    "- Synthetic data generation (e.g., **SMOTE**, **ADASYN**) may be needed to create balance.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. üìä **Applications Commonly Affected by Imbalanced Data**\n",
    "Imbalanced data is common in **high-stakes, real-world applications** where rare events are critical to detect.\n",
    "\n",
    "| Application | Majority Class | Minority Class |\n",
    "|--------------|----------------|----------------|\n",
    "| **Fraud Detection** | Legitimate transactions | Fraudulent transactions |\n",
    "| **Medical Diagnosis** | Healthy patients | Disease cases |\n",
    "| **Anomaly Detection** | Normal system behavior | Faults or cyberattacks |\n",
    "| **Credit Scoring** | Loan repayments | Loan defaults |\n",
    "\n",
    "These cases require models that **perform well on the minority class**, even if overall accuracy drops.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Summary\n",
    "\n",
    "| Problem | Description | Consequence |\n",
    "|----------|--------------|--------------|\n",
    "| **Bias Toward Majority Class** | Model prioritizes frequent classes | Poor detection of rare events |\n",
    "| **Misleading Metrics** | Accuracy hides poor recall for rare cases | False sense of success |\n",
    "| **Limited Minority Samples** | Insufficient data to learn patterns | Underfitting of minority class |\n",
    "| **Real-World Risk** | Errors on rare events are costly | Financial, medical, or operational losses |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Key Takeaways\n",
    "\n",
    "- Always **inspect class distributions** before training models.\n",
    "- Avoid relying solely on **accuracy** ‚Äî use **precision, recall, F1, ROC-AUC**, or **confusion matrices**.\n",
    "- Consider **resampling techniques** (oversampling minority, undersampling majority).\n",
    "- Use **cost-sensitive learning** or **ensemble methods** designed for imbalance (e.g., Balanced Random Forest, XGBoost with `scale_pos_weight`).\n",
    "- Imbalanced datasets require **special care in model evaluation and feature engineering**.\n",
    "\n",
    "---\n",
    "\n",
    "üìä **In short:**  \n",
    "> Imbalanced data doesn‚Äôt just lower model performance ‚Äî it **misleads evaluation** and hides critical failure risks.  \n",
    "> Always measure, visualize, and balance your dataset before trusting your model‚Äôs results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f29ad53",
   "metadata": {},
   "source": [
    "# üß© Techniques to Handle Imbalanced Data\n",
    "\n",
    "Handling imbalanced data is crucial to improving model performance and ensuring fair evaluation across classes.  \n",
    "Below are key **algorithmic and data-level strategies** used to address this challenge.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è 1. Algorithmic Solutions\n",
    "\n",
    "Algorithmic techniques modify the learning process so that the model gives more attention to the **minority class** during training.\n",
    "\n",
    "---\n",
    "\n",
    "### üßÆ a. Class Weights\n",
    "\n",
    "**Idea:** Assign **higher weights** to the minority class during training to penalize misclassification of rare samples more strongly.\n",
    "\n",
    "- This tells the model that errors on the minority class are **more costly**.\n",
    "- Many algorithms (e.g., Logistic Regression, SVM, Decision Tree, Random Forest, and XGBoost) support **built-in class weighting**.\n",
    "\n",
    "#### ‚úÖ Benefits:\n",
    "- Works directly within the algorithm (no need to modify the data).\n",
    "- Maintains the size and distribution of the original dataset.\n",
    "- Reduces model bias toward the majority class.\n",
    "\n",
    "#### ‚ö†Ô∏è When to Use:\n",
    "- When the dataset is too small for resampling techniques.\n",
    "- When the imbalance ratio is moderate (e.g., 1:10, 1:20).\n",
    "\n",
    "#### üíª Example (Scikit-learn Logistic Regression):\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Example: binary labels (0 = majority, 1 = minority)\n",
    "y = np.array([0]*90 + [1]*10)\n",
    "weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "print(\"Computed class weights:\", dict(zip(np.unique(y), weights)))\n",
    "\n",
    "# Apply class weights in model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543b0079",
   "metadata": {},
   "source": [
    "# üßÆ Evaluation Metrics for Imbalanced Data\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Why Special Metrics Are Needed\n",
    "\n",
    "In imbalanced datasets, **accuracy alone can be misleading** because predicting only the majority class can yield high accuracy but poor performance on the minority (positive) class.\n",
    "\n",
    "For example:\n",
    "- 95% of samples are class 0 (majority).\n",
    "- 5% are class 1 (minority).\n",
    "\n",
    "A model that predicts everything as class 0 would still have **95% accuracy**, yet **0% recall** for class 1 ‚Äî completely missing the minority class.\n",
    "\n",
    "To properly evaluate models under imbalance, we use **metrics that consider both false positives and false negatives.**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öñÔ∏è 1. F1-Score\n",
    "\n",
    "### üß† Definition\n",
    "The **F1-Score** is the **harmonic mean** of **Precision** and **Recall**, balancing the two.\n",
    "\n",
    "\\[\n",
    "F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- **Precision (Positive Predictive Value):**\n",
    "  \\[\n",
    "  Precision = \\frac{TP}{TP + FP}\n",
    "  \\]\n",
    "  Measures how many predicted positives are actually correct.\n",
    "- **Recall (Sensitivity):**\n",
    "  \\[\n",
    "  Recall = \\frac{TP}{TP + FN}\n",
    "  \\]\n",
    "  Measures how many actual positives were correctly identified.\n",
    "\n",
    "### ‚úÖ When to Use\n",
    "- When both **false positives (FP)** and **false negatives (FN)** are costly.\n",
    "- Particularly useful in **fraud detection**, **medical diagnosis**, and **risk analysis**.\n",
    "\n",
    "### üíª Example (Scikit-learn):\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "y_true = [0, 0, 1, 1, 1, 0, 1, 0]\n",
    "y_pred = [0, 0, 1, 0, 1, 0, 1, 0]\n",
    "\n",
    "print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "print(\"F1-Score:\", f1_score(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "784cee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "url = \"https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv\"\n",
    "df = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f05f0a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      " \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n",
      "None\n",
      "\n",
      " Class Distribution\n",
      "\n",
      "<bound method IndexOpsMixin.value_counts of 0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "284802    0\n",
      "284803    0\n",
      "284804    0\n",
      "284805    0\n",
      "284806    0\n",
      "Name: Class, Length: 284807, dtype: int64>\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Info:\\n \")\n",
    "print(df.info())\n",
    "print(\"\\n Class Distribution\\n\")\n",
    "print(df[\"Class\"].value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c8b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['Class'])\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe3e54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.99      0.76      0.86        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.99      0.88      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "0.9478093273747316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(\"\\n Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1])\n",
    "print(roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1f1dc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Class Distribution after SMOTE: \n",
      "\n",
      "Class\n",
      "0    227451\n",
      "1    227451\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state = 42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\n Class Distribution after SMOTE: \\n\")\n",
    "print(pd.Series(y_resampled.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bdb0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_smote = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "rf_model_smote.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred_smote = rf_model_smote.predict(X_test)\n",
    "print(\"\\n Classification Report (SMOTE):\\n\")\n",
    "print(classification_report(y_test, y_pred_smote))\n",
    "roc_auc_score = roc_auc_score(y_test, rf_model_smote.predict_proba(X_test)[:,1])\n",
    "print(roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a75aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
