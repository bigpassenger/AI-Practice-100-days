{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e9dffc7",
   "metadata": {},
   "source": [
    "# ü§ñ Concept of Ensemble Learning\n",
    "\n",
    "---\n",
    "\n",
    "## üìå What is Ensemble Learning?\n",
    "\n",
    "**Ensemble Learning** is a machine learning technique that combines the predictions of **multiple models** to produce a final output.  \n",
    "The idea is to **leverage the strengths of each individual model** to make a more accurate and robust prediction.\n",
    "\n",
    "### Key Idea:\n",
    "- Instead of relying on a single model, ensemble learning aggregates the predictions of several models, often **improving accuracy** and **reducing errors**.\n",
    "\n",
    "---\n",
    "\n",
    "## üìà Why Does Ensemble Learning Improve Performance?\n",
    "\n",
    "### 1. üîª Reduces Variance\n",
    "- **Multiple models reduce the impact of errors** from any single model.  \n",
    "- **Helps with overfitting**: By combining several models, the ensemble is less likely to fit noise in the training data.\n",
    "\n",
    "### 2. üî¥ Reduces Bias\n",
    "- By combining weak learners, ensemble methods can **improve accuracy**.  \n",
    "- **Bias reduction**: Ensemble learning can help improve underfitting by considering different perspectives of the data.\n",
    "\n",
    "### 3. üõ°Ô∏è Improves Robustness\n",
    "- **Better generalization**: Aggregating multiple models helps the ensemble make predictions that are **less sensitive to specific data peculiarities**.\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Types of Ensemble Learning Methods\n",
    "\n",
    "### 1. **Bagging (Bootstrap Aggregating)**\n",
    "- Combines predictions from multiple models trained on **different data subsets** (using bootstrapping).\n",
    "- Example: **Random Forest** (multiple decision trees).\n",
    "  \n",
    "### 2. **Boosting**\n",
    "- Sequentially trains models, where each model **corrects the errors** of the previous one.\n",
    "- Example: **AdaBoost**, **Gradient Boosting Machines (GBM)**, **XGBoost**.\n",
    "\n",
    "### 3. **Stacking**\n",
    "- Combines predictions of several models using a **meta-model** that learns how to best combine them.\n",
    "- Example: Using Logistic Regression on top of other classifiers (e.g., SVM, decision trees).\n",
    "\n",
    "---\n",
    "\n",
    "## üíº Applications of Ensemble Learning\n",
    "\n",
    "Ensemble methods are widely used in a variety of fields for their robustness and accuracy:\n",
    "\n",
    "- **Fraud Detection:** In financial services, ensemble models help identify fraudulent transactions.\n",
    "- **Medical Diagnoses:** Combining predictions from multiple models can improve diagnosis accuracy.\n",
    "- **Recommendation Systems:** Models can combine different algorithms to provide more accurate product or content recommendations.\n",
    "- **Predictive Analytics:** In various domains like weather forecasting, stock price prediction, etc., ensemble learning helps achieve more reliable predictions.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Final Thoughts\n",
    "\n",
    "- **Ensemble Learning** is a powerful technique to boost the performance of weak models and increase the robustness of predictions.\n",
    "- It's especially effective in **complex problems** where individual models may struggle to generalize across diverse scenarios.\n",
    "\n",
    "üìä **Key Takeaway:**  \n",
    "> Combining multiple models often leads to **better predictions** and **greater accuracy**, reducing the weaknesses of individual models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7322b7f",
   "metadata": {},
   "source": [
    "# üîÑ Types of Ensemble Methods\n",
    "\n",
    "Ensemble methods combine predictions from multiple models to improve overall performance. There are two primary techniques: **Bagging** and **Boosting**.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. üß≥ Bagging (Bootstrap Aggregating)\n",
    "\n",
    "### üìå What is Bagging?\n",
    "- **Bagging** trains multiple models independently on **different subsets** of data created through **bootstrapping** (sampling with replacement).\n",
    "- Predictions are combined by **averaging** (for regression) or **majority voting** (for classification).\n",
    "\n",
    "### üîß Key Characteristics:\n",
    "- **Reduces variance** without increasing bias.\n",
    "- Helps when individual models have **high variance**.\n",
    "\n",
    "### üõ†Ô∏è Example:\n",
    "- **Random Forest**: An ensemble of decision trees, where each tree is trained on a random subset of the data.\n",
    "\n",
    "### ‚úÖ Strengths:\n",
    "- Bagging works well for **high-variance models** (e.g., decision trees) by reducing the variance of predictions.\n",
    "- Models are trained **independently**, which makes bagging parallelizable.\n",
    "\n",
    "**Example Code (Random Forest with Bagging):**\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest example (bagging)\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47b668b",
   "metadata": {},
   "source": [
    "## üìä 3. Stacking (Stacked Generalization)\n",
    "\n",
    "### üìå What is Stacking?\n",
    "**Stacking** is an ensemble learning technique that combines the predictions of **multiple base models** (which can be of different types, such as decision trees, SVM, or neural networks) using a **meta-model** to learn how best to combine their outputs.\n",
    "\n",
    "Unlike methods like **bagging** and **boosting**, which use homogeneous models, stacking can work with **heterogeneous models** (models of different types). The key idea is to **train multiple base models** and use their predictions as inputs for a **meta-model**, which then makes the final prediction.\n",
    "\n",
    "### üîß How Does Stacking Work?\n",
    "1. **Base Models:** Train several different models (e.g., decision trees, logistic regression, support vector machines, neural networks) on the same dataset.\n",
    "2. **Meta-Model:** Use the predictions from the base models as inputs to a new model (meta-model). This meta-model learns the **best combination** of the base models' outputs to generate the final prediction.\n",
    "3. **Training Process:**\n",
    "   - First, split the data into training and validation sets.\n",
    "   - Train each base model on the training data.\n",
    "   - Then, make predictions on the validation data, which become the features for the meta-model.\n",
    "   - Finally, train the meta-model on these predictions to combine the outputs effectively.\n",
    "\n",
    "### üõ†Ô∏è Key Characteristics of Stacking:\n",
    "- **Heterogeneous Models:** Unlike bagging or boosting, stacking allows you to use a mix of different algorithms as base models (e.g., combining SVM, logistic regression, and neural networks).\n",
    "- **Meta-Learning:** The meta-model (often a simple linear model like logistic regression) learns the **optimal combination** of the base models' outputs.\n",
    "- **No Overfitting:** Since the base models are trained independently, stacking is less prone to overfitting compared to boosting methods, which are sequential.\n",
    "\n",
    "### ‚úÖ Strengths of Stacking:\n",
    "- **Combines Different Models:** Stacking can utilize the strengths of diverse model types, making it more flexible and powerful than bagging or boosting.\n",
    "- **Improves Accuracy:** By combining models that make different types of errors, stacking can often outperform individual models, especially in complex tasks.\n",
    "- **Versatility:** You can stack a wide variety of model types, making it suitable for diverse tasks (classification, regression).\n",
    "\n",
    "### üîß Example of Stacking with Scikit-Learn:\n",
    "Here's an example of how to implement **stacking** using scikit-learn's `StackingClassifier` and `StackingRegressor`.\n",
    "\n",
    "#### Step-by-step Example:\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Define base models\n",
    "base_learners = [\n",
    "    ('svm', SVC(probability=True)),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "]\n",
    "\n",
    "# Define meta-model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create Stacking Classifier\n",
    "stacked_model = StackingClassifier(estimators=base_learners, final_estimator=meta_model)\n",
    "\n",
    "# Train the model\n",
    "stacked_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = stacked_model.score(X_test, y_test)\n",
    "print(f'Accuracy of Stacked Model: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93a0f1e",
   "metadata": {},
   "source": [
    "Here is an expanded explanation of the commonly used ensemble methods (Random Forest, Gradient Boosting, AdaBoost, XGBoost, and Voting Classifier), written in a single Markdown block for your Jupyter Notebook:\n",
    "\n",
    "# ü§ñ Overview of Commonly Used Ensemble Methods\n",
    "\n",
    "Ensemble methods combine the outputs of multiple individual models to improve overall model performance. Below is a summary of some of the most popular ensemble techniques.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. üå≥ **Random Forest**\n",
    "\n",
    "### üìå What is Random Forest?\n",
    "**Random Forest** is an ensemble method that combines multiple **decision trees** using **bagging** (Bootstrap Aggregating). Each tree is trained on a different subset of the data, and the predictions are averaged (regression) or voted upon (classification).\n",
    "\n",
    "### üîß Key Characteristics:\n",
    "- **Bagging:** Reduces the risk of overfitting common in individual decision trees.\n",
    "- **Randomization:** Each tree is trained on a random subset of features and data.\n",
    "- **Aggregation:** Combines outputs of multiple decision trees to improve accuracy.\n",
    "\n",
    "### ‚úÖ Strengths:\n",
    "- **Reduces overfitting** compared to a single decision tree.\n",
    "- Works well with **high-dimensional data**.\n",
    "- Can handle **missing data** effectively.\n",
    "\n",
    "### üõ†Ô∏è Example (Random Forest Classifier):\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "2. ‚ö° Gradient Boosting\n",
    "üìå What is Gradient Boosting?\n",
    "\n",
    "Gradient Boosting builds models sequentially, where each new model focuses on minimizing the errors made by the previous models. The outputs of the models are combined through weighted averaging to make a final prediction.\n",
    "\n",
    "üîß Key Characteristics:\n",
    "\n",
    "Sequential Learning: Models are trained one after the other, with each model correcting the errors of the previous one.\n",
    "\n",
    "Bias and Variance: It helps reduce both bias and variance by focusing on hard-to-predict instances.\n",
    "\n",
    "‚úÖ Strengths:\n",
    "\n",
    "Highly accurate for both regression and classification tasks.\n",
    "\n",
    "Suitable for problems where high model accuracy is essential.\n",
    "\n",
    "üõ†Ô∏è Example (Gradient Boosting Classifier):\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Gradient Boosting model\n",
    "model = GradientBoostingClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "3. üîÑ AdaBoost\n",
    "üìå What is AdaBoost?\n",
    "\n",
    "AdaBoost adjusts the weights of models based on their performance. It focuses on misclassified instances by increasing the weight of incorrectly classified points, so subsequent models focus on correcting those mistakes.\n",
    "\n",
    "üîß Key Characteristics:\n",
    "\n",
    "Model Weighting: Focuses more on misclassified instances from previous models.\n",
    "\n",
    "Sequential Learning: Like Gradient Boosting, AdaBoost is a sequential method but does not involve gradient descent.\n",
    "\n",
    "‚úÖ Strengths:\n",
    "\n",
    "Reduces bias by focusing on hard-to-predict examples.\n",
    "\n",
    "Can significantly improve performance with weak learners (e.g., shallow decision trees).\n",
    "\n",
    "üõ†Ô∏è Example (AdaBoost Classifier):\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# AdaBoost model\n",
    "model = AdaBoostClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "4. üöÄ XGBoost\n",
    "üìå What is XGBoost?\n",
    "\n",
    "XGBoost (Extreme Gradient Boosting) is an optimized version of gradient boosting, specifically designed for speed and accuracy. It is a highly efficient library that performs boosting in a parallelized way, making it faster and more memory efficient.\n",
    "\n",
    "üîß Key Characteristics:\n",
    "\n",
    "Gradient Boosting: Uses the gradient boosting algorithm, but it adds regularization (L1 and L2) to control overfitting.\n",
    "\n",
    "Parallelization: It trains models in parallel, significantly speeding up computation.\n",
    "\n",
    "‚úÖ Strengths:\n",
    "\n",
    "Faster than regular Gradient Boosting.\n",
    "\n",
    "Handles missing data and outliers well.\n",
    "\n",
    "Often produces state-of-the-art performance on many datasets.\n",
    "\n",
    "üõ†Ô∏è Example (XGBoost Classifier):\n",
    "import xgboost as xgb\n",
    "\n",
    "# XGBoost model\n",
    "model = xgb.XGBClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "5. üó≥Ô∏è Voting Classifier\n",
    "üìå What is Voting Classifier?\n",
    "\n",
    "Voting Classifier combines predictions from multiple models (base learners) by using majority voting (classification) or averaging (regression) to make a final decision.\n",
    "\n",
    "üîß Key Characteristics:\n",
    "\n",
    "Simple Ensemble Method: Averages or votes across the predictions of several models.\n",
    "\n",
    "Base Learners: Can combine models of different types, such as decision trees, SVM, or logistic regression.\n",
    "\n",
    "‚úÖ Strengths:\n",
    "\n",
    "Combines diverse models to improve accuracy.\n",
    "\n",
    "Can use both hard voting (majority class) or soft voting (weighted average of probabilities).\n",
    "\n",
    "üõ†Ô∏è Example (Voting Classifier):\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define individual models\n",
    "model1 = LogisticRegression()\n",
    "model2 = SVC(probability=True)\n",
    "model3 = DecisionTreeClassifier()\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_model = VotingClassifier(estimators=[('lr', model1), ('svc', model2), ('dt', model3)], voting='soft')\n",
    "\n",
    "# Fit the model\n",
    "voting_model.fit(X_train, y_train)\n",
    "y_pred = voting_model.predict(X_test)\n",
    "\n",
    "üìä Summary of Ensemble Methods\n",
    "Method\tKey Idea\tStrengths\tUse Case\n",
    "Random Forest\tCombines decision trees via bagging.\tReduces overfitting, handles missing data\tClassification, Regression\n",
    "Gradient Boosting\tSequentially builds models, correcting errors.\tHighly accurate, reduces bias and variance\tClassification, Regression\n",
    "AdaBoost\tAdjusts model weights based on performance.\tFocuses on misclassified instances, reduces bias\tClassification\n",
    "XGBoost\tOptimized version of Gradient Boosting.\tFast, efficient, and accurate.\tClassification, Regression\n",
    "Voting Classifier\tCombines multiple models‚Äô predictions.\tSimple, can combine diverse models.\tClassification, Regression\n",
    "‚úÖ Final Thoughts\n",
    "\n",
    "Ensemble methods like Random Forest, Gradient Boosting, and XGBoost are commonly used for their high performance.\n",
    "\n",
    "Voting classifiers and AdaBoost offer flexibility by combining multiple algorithms to enhance accuracy.\n",
    "\n",
    "Ensemble methods are critical in real-world applications where performance and robustness are key.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Now you have a comprehensive explanation of the **commonly used ensemble methods**, with code examples and strengths. This is ready to use in your Jupyter Notebook, and if you need any further examples or explanations, feel free to ask!\n",
    "\n",
    "You said:\n",
    "write all these in a one cell jupyter markdown\n",
    "ChatGPT said:\n",
    "\n",
    "Sure! Here's the entire content written in one Jupyter Markdown cell, formatted for easy use:\n",
    "\n",
    "# ü§ñ Overview of Commonly Used Ensemble Methods\n",
    "\n",
    "Ensemble methods combine the outputs of multiple individual models to improve overall model performance. Below is a summary of some of the most popular ensemble techniques.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. üå≥ **Random Forest**\n",
    "\n",
    "### üìå What is Random Forest?\n",
    "**Random Forest** is an ensemble method that combines multiple **decision trees** using **bagging** (Bootstrap Aggregating). Each tree is trained on a different subset of the data, and the predictions are averaged (regression) or voted upon (classification).\n",
    "\n",
    "### üîß Key Characteristics:\n",
    "- **Bagging:** Reduces the risk of overfitting common in individual decision trees.\n",
    "- **Randomization:** Each tree is trained on a random subset of features and data.\n",
    "- **Aggregation:** Combines outputs of multiple decision trees to improve accuracy.\n",
    "\n",
    "### ‚úÖ Strengths:\n",
    "- **Reduces overfitting** compared to a single decision tree.\n",
    "- Works well with **high-dimensional data**.\n",
    "- Can handle **missing data** effectively.\n",
    "\n",
    "### üõ†Ô∏è Example (Random Forest Classifier):\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "2. ‚ö° Gradient Boosting\n",
    "üìå What is Gradient Boosting?\n",
    "\n",
    "Gradient Boosting builds models sequentially, where each new model focuses on minimizing the errors made by the previous models. The outputs of the models are combined through weighted averaging to make a final prediction.\n",
    "\n",
    "üîß Key Characteristics:\n",
    "\n",
    "Sequential Learning: Models are trained one after the other, with each model correcting the errors of the previous one.\n",
    "\n",
    "Bias and Variance: It helps reduce both bias and variance by focusing on hard-to-predict instances.\n",
    "\n",
    "‚úÖ Strengths:\n",
    "\n",
    "Highly accurate for both regression and classification tasks.\n",
    "\n",
    "Suitable for problems where high model accuracy is essential.\n",
    "\n",
    "üõ†Ô∏è Example (Gradient Boosting Classifier):\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Gradient Boosting model\n",
    "model = GradientBoostingClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "3. üîÑ AdaBoost\n",
    "üìå What is AdaBoost?\n",
    "\n",
    "AdaBoost adjusts the weights of models based on their performance. It focuses on misclassified instances by increasing the weight of incorrectly classified points, so subsequent models focus on correcting those mistakes.\n",
    "\n",
    "üîß Key Characteristics:\n",
    "\n",
    "Model Weighting: Focuses more on misclassified instances from previous models.\n",
    "\n",
    "Sequential Learning: Like Gradient Boosting, AdaBoost is a sequential method but does not involve gradient descent.\n",
    "\n",
    "‚úÖ Strengths:\n",
    "\n",
    "Reduces bias by focusing on hard-to-predict examples.\n",
    "\n",
    "Can significantly improve performance with weak learners (e.g., shallow decision trees).\n",
    "\n",
    "üõ†Ô∏è Example (AdaBoost Classifier):\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# AdaBoost model\n",
    "model = AdaBoostClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "4. üöÄ XGBoost\n",
    "üìå What is XGBoost?\n",
    "\n",
    "XGBoost (Extreme Gradient Boosting) is an optimized version of gradient boosting, specifically designed for speed and accuracy. It is a highly efficient library that performs boosting in a parallelized way, making it faster and more memory efficient.\n",
    "\n",
    "üîß Key Characteristics:\n",
    "\n",
    "Gradient Boosting: Uses the gradient boosting algorithm, but it adds regularization (L1 and L2) to control overfitting.\n",
    "\n",
    "Parallelization: It trains models in parallel, significantly speeding up computation.\n",
    "\n",
    "‚úÖ Strengths:\n",
    "\n",
    "Faster than regular Gradient Boosting.\n",
    "\n",
    "Handles missing data and outliers well.\n",
    "\n",
    "Often produces state-of-the-art performance on many datasets.\n",
    "\n",
    "üõ†Ô∏è Example (XGBoost Classifier):\n",
    "import xgboost as xgb\n",
    "\n",
    "# XGBoost model\n",
    "model = xgb.XGBClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "5. üó≥Ô∏è Voting Classifier\n",
    "üìå What is Voting Classifier?\n",
    "\n",
    "Voting Classifier combines predictions from multiple models (base learners) by using majority voting (classification) or averaging (regression) to make a final decision.\n",
    "\n",
    "üîß Key Characteristics:\n",
    "\n",
    "Simple Ensemble Method: Averages or votes across the predictions of several models.\n",
    "\n",
    "Base Learners: Can combine models of different types, such as decision trees, SVM, or logistic regression.\n",
    "\n",
    "‚úÖ Strengths:\n",
    "\n",
    "Combines diverse models to improve accuracy.\n",
    "\n",
    "Can use both hard voting (majority class) or soft voting (weighted average of probabilities).\n",
    "\n",
    "üõ†Ô∏è Example (Voting Classifier):\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define individual models\n",
    "model1 = LogisticRegression()\n",
    "model2 = SVC(probability=True)\n",
    "model3 = DecisionTreeClassifier()\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_model = VotingClassifier(estimators=[('lr', model1), ('svc', model2), ('dt', model3)], voting='soft')\n",
    "\n",
    "# Fit the model\n",
    "voting_model.fit(X_train, y_train)\n",
    "y_pred = voting_model.predict(X_test)\n",
    "\n",
    "üìä Summary of Ensemble Methods\n",
    "Method\tKey Idea\tStrengths\tUse Case\n",
    "Random Forest\tCombines decision trees via bagging.\tReduces overfitting, handles missing data\tClassification, Regression\n",
    "Gradient Boosting\tSequentially builds models, correcting errors.\tHighly accurate, reduces bias and variance\tClassification, Regression\n",
    "AdaBoost\tAdjusts model weights based on performance.\tFocuses on misclassified instances, reduces bias\tClassification\n",
    "XGBoost\tOptimized version of Gradient Boosting.\tFast, efficient, and accurate.\tClassification, Regression\n",
    "Voting Classifier\tCombines multiple models‚Äô predictions.\tSimple, can combine diverse models.\tClassification, Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "383bf6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import  numpy as np\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_iris()\n",
    "X,y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6484dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28eed44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression()\n",
    "dt_model = DecisionTreeClassifier()\n",
    "knn_model = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6246c0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KNeighborsClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_neighbors',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_neighbors&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">weights&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;uniform&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('algorithm',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">algorithm&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('leaf_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">leaf_size&nbsp;</td>\n",
       "            <td class=\"value\">30</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('p',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">p&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">metric&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;minkowski&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('metric_params',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">metric_params&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.fit(X_train, y_train)\n",
    "dt_model.fit(X_train, y_train)\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7b63081",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('log_reg', log_model),\n",
    "        ('decision_tree', dt_model),\n",
    "        ('knn', knn_model)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8408c09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model.fit(X_train, y_train)\n",
    "y_pred_ensemble = ensemble_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a9be8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9158f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = log_model.predict(X_test)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "y_pred_knn = knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4c46ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred_log )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4923b444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred_dt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa33f9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f21ca1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
